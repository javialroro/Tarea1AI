# ‚úÖ To-Do List ‚Äì Proyecto Student Performance

## üìÇ Lectura del Dataset
- [ x] Cargar el dataset con Pandas  
  - [ x] `pd.read_csv("Student_Performance.csv")`  
  - [ x] Guardar en un DataFrame llamado `df`.
- [ ] Explorar estructura del dataset  
  - [ x] Revisar filas y columnas ‚Üí `df.shape`  
  - [ x] Ver columnas y tipos de datos ‚Üí `df.info()`  
- [ X] Revisar calidad b√°sica  
  - [ X] Verificar nulos ‚Üí `df.isna().sum()`  
  - [ X] Detectar duplicados ‚Üí `df.duplicated().sum()`
- [ ] Obtener estad√≠sticas descriptivas  
  - [ X] `df.describe()` ‚Üí mean, std, min, cuartiles, max  
  - [ X] `df.describe(include='all')` para incluir categ√≥ricas
- [ ] Interpretar resultados  
  - [ ] Confirmar tipos de datos correctos  
  - [ ] Identificar rangos de valores  
  - [ ] Decidir tratamiento de duplicados  
  - [ ] Concluir si el dataset est√° limpio o si requiere ajustes  

---

## üîç EDA (Exploratory Data Analysis)
- [ ] Histogramas y Boxplots  
  - [ ] Generar histogramas de variables num√©ricas  
  - [ ] Generar boxplots de esas variables  
  - [ ] Interpretar distribuciones y outliers
- [ ] Diagramas de dispersi√≥n (vs target)  
  - [ ] Hacer scatter plots contra *Performance Index*  
  - [ ] Interpretar relaciones lineales/no lineales y outliers
- [ ] Matriz de correlaci√≥n (heatmap)  
  - [ ] Calcular correlaciones  
  - [ ] Visualizar con mapa de calor  
  - [ ] Interpretar correlaciones fuertes y colinealidades
- [ ] Detecci√≥n y tratamiento de outliers  
  - [ ] Revisar boxplots  
  - [ ] Decidir mantener, winsorizar o eliminar  
  - [ ] Documentar decisi√≥n
- [ ] Interpretaci√≥n global  
  - [ ] Identificar variables m√°s importantes  
  - [ ] Concluir sobre outliers, distribuciones y posibles transformaciones  

---

## ‚úÇÔ∏è Divisi√≥n del Dataset
- [ x] Preparaci√≥n  
  - [ x] Definir `X` (features) y `y` (target)  
  - [ x] Convertir categ√≥ricas a num√©ricas  
  - [x ] Preparar funciones para escalado  
  - [ x] A√±adir columna de 1‚Äôs (bias)
- [ x] Muestreo aleatorio (70/15/15)  
  - [ X] Barajar √≠ndices  
  - [ X] Generar splits `train/val/test`  
  - [x ] Escalar con estad√≠sticas del train
- [x ] Muestreo estratificado  
  - [ x] Binear *Performance Index*  
  - [ x] Dividir cada estrato en 70/15/15  
  - [ x] Escalar igual que aleatorio  
  - [ x] A√±adir bias
- [ ] Validaci√≥n de particiones  
  - [ ] Revisar tama√±os de splits  
  - [ ] Comparar distribuciones de *Performance Index*  
- [ ] Documentaci√≥n  
  - [ ] Tabla/figura comparando aleatorio vs estratificado  
  - [ ] Justificar elecci√≥n  

---

## üìà Implementaci√≥n de Regresi√≥n Lineal
- [ ] Preparaci√≥n de datos  
  - [ ] Confirmar target y features  
  - [ ] Codificar categ√≥ricas  
  - [ ] Dividir en train/val/test  
  - [ ] Escalar con train  
  - [ ] A√±adir bias  
  - [ ] Fijar semilla
- [ ] Definiciones matem√°ticas  
  - [ ] Hip√≥tesis: ≈∑ = XŒ∏  
  - [ ] Costo: MSE  
  - [ ] Gradiente: ‚àáŒ∏L = (2/m)¬∑X·µÄ(XŒ∏ ‚àí y)
- [ ] Inicializaci√≥n e hiperpar√°metros  
  - [ ] Inicializar Œ∏  
  - [ ] Seleccionar learning rate Œ±  
  - [ ] Definir n√∫mero de √©pocas  
  - [ ] (Opcional) Regularizaci√≥n L2  
- [ ] Batch Gradient Descent  
  - [ ] Forward pass  
  - [ ] Calcular gradiente  
  - [ ] Actualizar Œ∏  
  - [ ] Registrar MSE (train/val)  
  - [ ] Proteger contra errores num√©ricos
- [ ] Monitoreo y parada  
  - [ ] Graficar p√©rdidas train vs val  
  - [ ] Implementar early stopping (opcional)  
  - [ ] Guardar mejor Œ∏
- [ ] Evaluaci√≥n final  
  - [ ] Predecir en test  
  - [ ] Calcular MSE y R¬≤  
  - [ ] Graficar residuos vs predicciones  
  - [ ] Guardar artefactos (`theta.csv`, m√©tricas, historial)
- [ ] Mini-Batch Gradient Descent (opcional)  
  - [ ] Definir batch_size  
  - [ ] Implementar mini-batch loop  
  - [ ] Comparar convergencia vs batch
- [ ] Experimentos y reporte  
  - [ ] B√∫squeda de hiperpar√°metros  
  - [ ] Comparar splits aleatorio vs estratificado  
  - [ ] Redactar conclusiones  

---

## üìä Evaluaci√≥n del Modelo
- [ ] Definir m√©tricas  
  - [ ] Implementar MSE manualmente  
  - [ ] (Opcional) Implementar R¬≤
- [ ] Calcular durante el entrenamiento  
  - [ ] MSE en train y val  
  - [ ] Guardar historial
- [ ] Visualizaci√≥n  
  - [ ] Graficar curva de p√©rdidas (train vs val)  
  - [ ] A√±adir t√≠tulo, ejes, leyenda
- [ ] Evaluaci√≥n final en test  
  - [ ] Calcular MSE en test  
  - [ ] Guardar en CSV
- [ ] An√°lisis e interpretaci√≥n  
  - [ ] Comparar train vs val  
  - [ ] Evaluar overfitting/underfitting  
  - [ ] Comparar aleatorio vs estratificado  
- [ ] Entregables  
  - [ ] Curva de p√©rdidas  
  - [ ] MSE en test  
  - [ ] Interpretaci√≥n escrita  
  - [ ] Archivos en `/results`

---

## üîÆ An√°lisis Final
- [ ] Predicciones en test  
  - [ ] Calcular ≈∑_test = X_test Œ∏  
  - [ ] Comparar con y_test
- [ ] M√©trica final  
  - [ ] Reportar MSE  
  - [ ] (Opcional) Reportar R¬≤
- [ ] Gr√°fico de residuos  
  - [ ] X = predicciones, Y = residuos  
  - [ ] L√≠nea en 0  
  - [ ] Analizar dispersi√≥n y outliers
- [ ] Interpretaci√≥n  
  - [ ] Revisar residuos centrados en 0  
  - [ ] Detectar heterocedasticidad  
  - [ ] Evaluar ajuste lineal
- [ ] Comparaci√≥n de splits  
  - [ ] Evaluar diferencias entre aleatorio y estratificado
- [ ] S√≠ntesis  
  - [ ] Evaluar si regresi√≥n lineal es suficiente  
  - [ ] Recomendaciones (regularizaci√≥n, modelos m√°s complejos, etc.)

---
